{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "hRt9s5I1P2qS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# **Recent search**\n",
    "\n",
    "The recent search endpoint allows you to programmatically access filtered public Tweets posted over the last week, and is available to all developers who have a developer account and are using keys and tokens from anÂ AppÂ within aÂ Project.\n",
    "\n",
    "You can authenticate your requests withÂ OAuth 1.0a User Context,Â OAuth 2.0 App-Only, orÂ OAuth 2.0 Authorization Code with PKCE. However, if you would like to receiveÂ private metrics, or a breakdown of organic and promoted metrics within your Tweet results, you will have to useÂ OAuth 1.0a User ContextÂ or OAuth 2.0 Authorization Code with PKCE, and pass userÂ Access TokensÂ that are associated with the user that published the given content.Â \n",
    "\n",
    "This endpoint can deliver up to 100 Tweets per request in reverse-chronological order, andÂ paginationÂ tokens are provided for paging through large sets of matching Tweets.Â \n",
    "\n",
    "When using a Project with Essential or Elevated access, you can use the basic set ofÂ operatorsÂ and can make queries up to 512 characters long. When using a Project with Academic Research access or Enterprise access, you have access to additional operators.\n",
    "\n",
    "Rate limit: App rate limit (Application-only): 450 requests per 15-minute window shared among all users of your app"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "21NaYdhRr9i7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set up\n",
    "\n",
    "1. Tokens and keys should not be kept in colab notebooks. I advise you to \n",
    "delete them from the code after every use. Here we create an environmental variable and save the token in it. It will be deleted on restart of the runtime.\n",
    "\n",
    "2. In order to efficiently save your data it's best to connect the notebook with your Google Drive (n.b: this doesn't work with university's account - you need to use Gmail). This way you don't risk losing your data if the notebook malfunctions and you can later access it from a notebook again. \n",
    "\n",
    "3. Libraries that we need (for now) are *requests*, to handle our API requests, and *pandas* to easily view and store the results.\n",
    "\n",
    "4. Colab environment offers you loads of pre-installe dpython libraries (you can check which ones by executing `!pip freeze`), *however* if your library is not on the list you need to manually install it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gNFOaZPIxyS2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TOKEN'] = \"AAAAAAAAAAAAAAAAAAAAACiskgEAAAAACR0Ob5x7EAcEyWB1yK08z38ONeE%3DFDLKfajgEnOwF4Ult0L1HcalsR01XnaKUztJgdClTQJaWTRqbE\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREAT PATH : "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code generates a \"Path\" object that specifies the destination directory for storing files or codes, ensuring efficient and reliable data organization :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/other/job/students_project/network_science/maryam_project/data/gymnastics/'\n",
    "error_log_path = 'D:/other/job/students_project/network_science/maryam_project/data/gymnastics/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nwy6MeGur9i-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8ge5EaEur9jA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd \n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If you need to download a library, use the following code, just specify the name of the library you need (here we downloaded emoji library)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 1: authenticate\n",
    "\n",
    "In order to authenticate our request, we need to create a request header and add an authorization field. You can authorize a request by using the bearer token, or the API consumer/secret keys. Here we do it with bearer token for the sake of simplicity.\n",
    "\n",
    "You can read more about it here: https://developer.twitter.com/en/docs/authentication/overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "### Set up headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_headers(bearer_token):\n",
    "        headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "        return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "headers = create_headers(os.environ['TOKEN'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 2: build a search query\n",
    "\n",
    "**Ingredients**: endpoint, parameters and operators\n",
    "\n",
    "For endpoint we use: https://api.twitter.com/2/tweets/search/recent\n",
    "\n",
    "**Example parameters**: \n",
    "\n",
    "* query: the text of your search (required) - max 512 chars\n",
    "* end_time: the newest date for your tweets\n",
    "* start_time: the oldest date for your tweets\n",
    "(format for date: YYYY-MM-DDTHH:mm:ssZ (ISO 8601/RFC 3339))\n",
    "* max_results: between 10 (default) and 100\n",
    "* tweet_fields: which fields to get (if empty, you only get id&text&edit \n",
    "history)\n",
    "* user_fields, place_fields, expansions\n",
    "* next_token: to get the next page of results \n",
    "\n",
    "\n",
    "**Example operators**: keyword (menstruation), exact phrase(\"sexual education\"), hashtag (\"#metoo\"), emoji (ðŸ˜¬), logical operators (AND = a blank space), OR, NOT), from: or to: (tweets from a user or directed to a user), @ (tweets that mention the user, @NASA), is:retweet, is: reply , is:quote, lang: (\"en\")\n",
    "\n",
    "Grouping is done with brackets. F.e (#prolife abortion) OR (#prochoice abortion)\n",
    "\n",
    "See more here: \n",
    "\n",
    "Operators: https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query\n",
    "\n",
    "Parameters: https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_url(query, start_time, end_time, max_results, expansions, tweet_fields, user_fields, place_fields, endpoint):\n",
    "    \n",
    "    search_url = endpoint #Change to the endpoint you want to collect data from\n",
    "\n",
    "    #change params based on the endpoint you are using\n",
    "    #also can request different fields, e.g ids of users ... \n",
    "    query_params = {'query': query,\n",
    "                    'end_time': end_time,\n",
    "                    'start_time': start_time,\n",
    "                    'max_results': max_results,\n",
    "                    'expansions': expansions,\n",
    "                    'tweet.fields': tweet_fields,\n",
    "                    'user.fields': user_fields,\n",
    "                    'place.fields': place_fields}\n",
    "\n",
    "    return (search_url, query_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def connect_to_endpoint(url, headers, params, next_token = None):\n",
    "    if next_token is not None and next_token != '':\n",
    "      params['next_token'] = next_token\n",
    "    response = requests.request(\"GET\", url, headers = headers, params = params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(query, start_time, end_time, max_results, expansions, tweet_fields, user_fields, place_fields, endpoint, next_token=\"\"):\n",
    "  \n",
    "  results = []\n",
    "  count = 0\n",
    "  batch = 1\n",
    "  lastTweetTime = \"NULL\"\n",
    "\n",
    "  while next_token is not None:\n",
    "  # while count < 1:\n",
    "    try:\n",
    "      url = create_url(query, start_time, end_time, max_results, expansions, tweet_fields, user_fields, place_fields, endpoint)\n",
    "      json_response = connect_to_endpoint(url[0], headers, url[1], next_token)\n",
    "      #if we have results, they will be in the field 'data' of our response\n",
    "      if \"data\" in json_response:\n",
    "        results.extend(json_response[\"data\"])\n",
    "        print(str(count) + \": \" + str(len(json_response[\"data\"])) + \" Tweets downloaded in this batch. with last tweet: \" + lastTweetTime)\n",
    "        lastTweetTime = json_response['data'][0]['created_at']\n",
    "        count += 1\n",
    "      #the next_token is added to the field 'meta' of our response\n",
    "      if \"meta\" in json_response:\n",
    "        if \"next_token\" in json_response[\"meta\"].keys():\n",
    "          next_token = json_response[\"meta\"][\"next_token\"]          \n",
    "        else:\n",
    "          next_token = None\n",
    "      else:\n",
    "        next_token = None\n",
    "\n",
    "      if count >= 30:\n",
    "         tweets_df = pd.DataFrame(results)\n",
    "         tweets_df.to_pickle(path + \"tweets_\" + lastTweetTime[:10] + \"_\" + str(batch) + \".pkl\")\n",
    "         print(\"Tweets batch %d stored in pkl file\" % batch)\n",
    "         batch += 1\n",
    "         count = 0\n",
    "      \n",
    "      #to control the rate limit we need to slow down our download\n",
    "      time.sleep(3)\n",
    "\n",
    "    except Exception as e:\n",
    "      print(\"Error occured\", e)\n",
    "      print(\"Next token value\", next_token)\n",
    "      error_log = {\"Error\":e, \"Next token\":next_token, \"Day\":start_time, \n",
    "                   \"Downloaded\":len(results)}\n",
    "      # pd.DataFrame.from_dict(error_log, orient=\"index\").to_csv(error_log_path+start_time+\"_\"+next_token+\".csv\")\n",
    "      return results\n",
    "\n",
    "  print(\"Done\")\n",
    "  \n",
    "  return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 3: download and save the data\n",
    "\n",
    "We call the function, filling in the desired parameters. We convert the data into a pandas dataframe to easily manipulate it (view, edit, save). We save the data in the PICKLE format, so we can recover the exact data types later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 97 Tweets downloaded in this batch. with last tweet: NULL\n",
      "1: 95 Tweets downloaded in this batch. with last tweet: 2021-08-14T22:02:43.000Z\n",
      "2: 95 Tweets downloaded in this batch. with last tweet: 2021-08-13T09:32:21.000Z\n",
      "3: 96 Tweets downloaded in this batch. with last tweet: 2021-08-11T15:42:43.000Z\n",
      "4: 99 Tweets downloaded in this batch. with last tweet: 2021-08-10T08:06:09.000Z\n",
      "5: 96 Tweets downloaded in this batch. with last tweet: 2021-08-09T06:00:04.000Z\n",
      "6: 95 Tweets downloaded in this batch. with last tweet: 2021-08-08T12:32:00.000Z\n",
      "7: 100 Tweets downloaded in this batch. with last tweet: 2021-08-08T01:35:11.000Z\n",
      "8: 95 Tweets downloaded in this batch. with last tweet: 2021-08-07T15:03:55.000Z\n",
      "9: 100 Tweets downloaded in this batch. with last tweet: 2021-08-07T11:49:22.000Z\n",
      "10: 98 Tweets downloaded in this batch. with last tweet: 2021-08-07T00:09:46.000Z\n",
      "11: 94 Tweets downloaded in this batch. with last tweet: 2021-08-06T19:29:32.000Z\n",
      "12: 97 Tweets downloaded in this batch. with last tweet: 2021-08-06T09:45:04.000Z\n",
      "13: 99 Tweets downloaded in this batch. with last tweet: 2021-08-05T20:01:20.000Z\n",
      "14: 99 Tweets downloaded in this batch. with last tweet: 2021-08-05T11:52:53.000Z\n",
      "15: 100 Tweets downloaded in this batch. with last tweet: 2021-08-05T02:18:24.000Z\n",
      "16: 95 Tweets downloaded in this batch. with last tweet: 2021-08-04T17:28:25.000Z\n",
      "17: 96 Tweets downloaded in this batch. with last tweet: 2021-08-04T13:09:09.000Z\n",
      "18: 98 Tweets downloaded in this batch. with last tweet: 2021-08-04T06:36:19.000Z\n",
      "19: 95 Tweets downloaded in this batch. with last tweet: 2021-08-04T01:46:12.000Z\n",
      "20: 93 Tweets downloaded in this batch. with last tweet: 2021-08-03T23:06:28.000Z\n",
      "21: 98 Tweets downloaded in this batch. with last tweet: 2021-08-03T18:24:30.000Z\n",
      "22: 94 Tweets downloaded in this batch. with last tweet: 2021-08-03T15:42:53.000Z\n",
      "23: 97 Tweets downloaded in this batch. with last tweet: 2021-08-03T14:09:17.000Z\n",
      "24: 96 Tweets downloaded in this batch. with last tweet: 2021-08-03T11:23:40.000Z\n",
      "25: 96 Tweets downloaded in this batch. with last tweet: 2021-08-03T10:11:40.000Z\n",
      "26: 96 Tweets downloaded in this batch. with last tweet: 2021-08-03T09:43:45.000Z\n",
      "27: 97 Tweets downloaded in this batch. with last tweet: 2021-08-03T09:20:12.000Z\n",
      "28: 96 Tweets downloaded in this batch. with last tweet: 2021-08-03T09:11:13.000Z\n",
      "29: 97 Tweets downloaded in this batch. with last tweet: 2021-08-03T07:46:24.000Z\n",
      "Tweets batch 1 stored in pkl file\n",
      "0: 98 Tweets downloaded in this batch. with last tweet: 2021-08-03T02:01:23.000Z\n",
      "1: 98 Tweets downloaded in this batch. with last tweet: 2021-08-02T23:47:57.000Z\n",
      "2: 100 Tweets downloaded in this batch. with last tweet: 2021-08-02T22:33:03.000Z\n",
      "3: 99 Tweets downloaded in this batch. with last tweet: 2021-08-02T18:04:55.000Z\n",
      "4: 98 Tweets downloaded in this batch. with last tweet: 2021-08-02T13:57:18.000Z\n",
      "5: 97 Tweets downloaded in this batch. with last tweet: 2021-08-02T11:31:15.000Z\n",
      "6: 97 Tweets downloaded in this batch. with last tweet: 2021-08-02T10:43:32.000Z\n",
      "7: 96 Tweets downloaded in this batch. with last tweet: 2021-08-02T10:20:03.000Z\n",
      "8: 97 Tweets downloaded in this batch. with last tweet: 2021-08-02T09:45:55.000Z\n",
      "9: 91 Tweets downloaded in this batch. with last tweet: 2021-08-02T09:25:43.000Z\n",
      "10: 81 Tweets downloaded in this batch. with last tweet: 2021-08-02T08:57:33.000Z\n",
      "11: 98 Tweets downloaded in this batch. with last tweet: 2021-08-02T04:47:11.000Z\n",
      "12: 95 Tweets downloaded in this batch. with last tweet: 2021-08-02T01:01:57.000Z\n",
      "13: 92 Tweets downloaded in this batch. with last tweet: 2021-08-01T22:35:13.000Z\n",
      "14: 91 Tweets downloaded in this batch. with last tweet: 2021-08-01T18:15:50.000Z\n",
      "15: 95 Tweets downloaded in this batch. with last tweet: 2021-08-01T15:03:39.000Z\n",
      "16: 97 Tweets downloaded in this batch. with last tweet: 2021-08-01T11:55:13.000Z\n",
      "17: 100 Tweets downloaded in this batch. with last tweet: 2021-08-01T10:50:22.000Z\n",
      "18: 98 Tweets downloaded in this batch. with last tweet: 2021-08-01T10:26:33.000Z\n",
      "19: 98 Tweets downloaded in this batch. with last tweet: 2021-08-01T10:10:23.000Z\n",
      "20: 97 Tweets downloaded in this batch. with last tweet: 2021-08-01T09:48:25.000Z\n",
      "21: 97 Tweets downloaded in this batch. with last tweet: 2021-08-01T09:16:44.000Z\n",
      "22: 95 Tweets downloaded in this batch. with last tweet: 2021-08-01T08:35:02.000Z\n",
      "23: 95 Tweets downloaded in this batch. with last tweet: 2021-08-01T02:27:40.000Z\n",
      "24: 98 Tweets downloaded in this batch. with last tweet: 2021-07-31T15:49:28.000Z\n",
      "25: 90 Tweets downloaded in this batch. with last tweet: 2021-07-31T05:55:20.000Z\n",
      "26: 97 Tweets downloaded in this batch. with last tweet: 2021-07-31T00:28:47.000Z\n",
      "27: 100 Tweets downloaded in this batch. with last tweet: 2021-07-30T17:31:51.000Z\n",
      "28: 94 Tweets downloaded in this batch. with last tweet: 2021-07-30T12:32:48.000Z\n",
      "29: 96 Tweets downloaded in this batch. with last tweet: 2021-07-30T08:34:14.000Z\n",
      "Tweets batch 2 stored in pkl file\n",
      "0: 98 Tweets downloaded in this batch. with last tweet: 2021-07-30T03:39:14.000Z\n",
      "1: 91 Tweets downloaded in this batch. with last tweet: 2021-07-30T02:36:31.000Z\n",
      "2: 97 Tweets downloaded in this batch. with last tweet: 2021-07-30T00:56:21.000Z\n",
      "3: 97 Tweets downloaded in this batch. with last tweet: 2021-07-29T23:19:22.000Z\n",
      "4: 93 Tweets downloaded in this batch. with last tweet: 2021-07-29T21:00:48.000Z\n",
      "5: 95 Tweets downloaded in this batch. with last tweet: 2021-07-29T18:45:54.000Z\n",
      "6: 97 Tweets downloaded in this batch. with last tweet: 2021-07-29T16:36:56.000Z\n",
      "7: 98 Tweets downloaded in this batch. with last tweet: 2021-07-29T15:06:45.000Z\n",
      "8: 96 Tweets downloaded in this batch. with last tweet: 2021-07-29T14:15:29.000Z\n",
      "9: 97 Tweets downloaded in this batch. with last tweet: 2021-07-29T13:31:26.000Z\n",
      "10: 97 Tweets downloaded in this batch. with last tweet: 2021-07-29T13:12:40.000Z\n",
      "11: 98 Tweets downloaded in this batch. with last tweet: 2021-07-29T13:02:46.000Z\n",
      "12: 98 Tweets downloaded in this batch. with last tweet: 2021-07-29T12:58:04.000Z\n",
      "13: 97 Tweets downloaded in this batch. with last tweet: 2021-07-29T12:41:16.000Z\n",
      "14: 99 Tweets downloaded in this batch. with last tweet: 2021-07-29T12:16:59.000Z\n",
      "15: 98 Tweets downloaded in this batch. with last tweet: 2021-07-29T11:50:58.000Z\n",
      "16: 93 Tweets downloaded in this batch. with last tweet: 2021-07-29T11:10:53.000Z\n",
      "17: 90 Tweets downloaded in this batch. with last tweet: 2021-07-29T10:24:48.000Z\n",
      "18: 97 Tweets downloaded in this batch. with last tweet: 2021-07-29T04:25:24.000Z\n",
      "19: 98 Tweets downloaded in this batch. with last tweet: 2021-07-29T02:03:08.000Z\n",
      "20: 99 Tweets downloaded in this batch. with last tweet: 2021-07-29T00:21:28.000Z\n",
      "21: 94 Tweets downloaded in this batch. with last tweet: 2021-07-28T21:21:10.000Z\n",
      "22: 82 Tweets downloaded in this batch. with last tweet: 2021-07-28T18:54:16.000Z\n",
      "23: 95 Tweets downloaded in this batch. with last tweet: 2021-07-28T16:58:18.000Z\n",
      "24: 96 Tweets downloaded in this batch. with last tweet: 2021-07-28T16:06:15.000Z\n",
      "25: 91 Tweets downloaded in this batch. with last tweet: 2021-07-28T15:02:22.000Z\n",
      "26: 93 Tweets downloaded in this batch. with last tweet: 2021-07-28T14:19:24.000Z\n",
      "27: 94 Tweets downloaded in this batch. with last tweet: 2021-07-28T13:47:30.000Z\n",
      "28: 96 Tweets downloaded in this batch. with last tweet: 2021-07-28T13:11:38.000Z\n",
      "29: 92 Tweets downloaded in this batch. with last tweet: 2021-07-28T12:27:28.000Z\n",
      "Tweets batch 3 stored in pkl file\n",
      "0: 87 Tweets downloaded in this batch. with last tweet: 2021-07-28T11:12:28.000Z\n",
      "1: 95 Tweets downloaded in this batch. with last tweet: 2021-07-28T10:04:19.000Z\n",
      "2: 98 Tweets downloaded in this batch. with last tweet: 2021-07-28T07:22:05.000Z\n",
      "3: 99 Tweets downloaded in this batch. with last tweet: 2021-07-28T05:42:13.000Z\n",
      "4: 96 Tweets downloaded in this batch. with last tweet: 2021-07-28T03:19:20.000Z\n",
      "5: 97 Tweets downloaded in this batch. with last tweet: 2021-07-28T01:58:48.000Z\n",
      "6: 96 Tweets downloaded in this batch. with last tweet: 2021-07-28T01:22:12.000Z\n",
      "7: 97 Tweets downloaded in this batch. with last tweet: 2021-07-28T01:01:57.000Z\n",
      "8: 91 Tweets downloaded in this batch. with last tweet: 2021-07-28T00:35:47.000Z\n",
      "9: 98 Tweets downloaded in this batch. with last tweet: 2021-07-27T23:11:41.000Z\n",
      "10: 95 Tweets downloaded in this batch. with last tweet: 2021-07-27T21:37:25.000Z\n",
      "11: 95 Tweets downloaded in this batch. with last tweet: 2021-07-27T19:58:39.000Z\n",
      "12: 96 Tweets downloaded in this batch. with last tweet: 2021-07-27T18:50:11.000Z\n",
      "13: 97 Tweets downloaded in this batch. with last tweet: 2021-07-27T17:47:03.000Z\n",
      "14: 91 Tweets downloaded in this batch. with last tweet: 2021-07-27T16:58:30.000Z\n",
      "15: 91 Tweets downloaded in this batch. with last tweet: 2021-07-27T16:17:29.000Z\n",
      "16: 94 Tweets downloaded in this batch. with last tweet: 2021-07-27T15:40:52.000Z\n",
      "17: 94 Tweets downloaded in this batch. with last tweet: 2021-07-27T14:59:04.000Z\n",
      "18: 95 Tweets downloaded in this batch. with last tweet: 2021-07-27T14:15:42.000Z\n",
      "19: 97 Tweets downloaded in this batch. with last tweet: 2021-07-27T13:38:04.000Z\n",
      "20: 98 Tweets downloaded in this batch. with last tweet: 2021-07-27T13:20:53.000Z\n",
      "21: 97 Tweets downloaded in this batch. with last tweet: 2021-07-27T13:08:48.000Z\n",
      "22: 97 Tweets downloaded in this batch. with last tweet: 2021-07-27T13:01:08.000Z\n",
      "23: 95 Tweets downloaded in this batch. with last tweet: 2021-07-27T12:56:42.000Z\n",
      "24: 95 Tweets downloaded in this batch. with last tweet: 2021-07-27T12:54:22.000Z\n",
      "25: 93 Tweets downloaded in this batch. with last tweet: 2021-07-27T12:51:19.000Z\n",
      "26: 98 Tweets downloaded in this batch. with last tweet: 2021-07-27T12:42:12.000Z\n",
      "27: 98 Tweets downloaded in this batch. with last tweet: 2021-07-27T12:33:05.000Z\n",
      "28: 97 Tweets downloaded in this batch. with last tweet: 2021-07-27T12:22:31.000Z\n",
      "29: 96 Tweets downloaded in this batch. with last tweet: 2021-07-27T12:15:45.000Z\n",
      "Tweets batch 4 stored in pkl file\n",
      "0: 98 Tweets downloaded in this batch. with last tweet: 2021-07-27T12:06:33.000Z\n",
      "1: 97 Tweets downloaded in this batch. with last tweet: 2021-07-27T11:56:28.000Z\n",
      "2: 98 Tweets downloaded in this batch. with last tweet: 2021-07-27T11:48:23.000Z\n",
      "3: 97 Tweets downloaded in this batch. with last tweet: 2021-07-27T11:40:20.000Z\n",
      "4: 96 Tweets downloaded in this batch. with last tweet: 2021-07-27T11:32:45.000Z\n",
      "5: 97 Tweets downloaded in this batch. with last tweet: 2021-07-27T11:25:31.000Z\n",
      "6: 99 Tweets downloaded in this batch. with last tweet: 2021-07-27T11:11:57.000Z\n",
      "7: 89 Tweets downloaded in this batch. with last tweet: 2021-07-27T10:57:38.000Z\n",
      "8: 96 Tweets downloaded in this batch. with last tweet: 2021-07-27T10:23:44.000Z\n",
      "9: 96 Tweets downloaded in this batch. with last tweet: 2021-07-27T03:46:33.000Z\n",
      "10: 96 Tweets downloaded in this batch. with last tweet: 2021-07-27T01:17:10.000Z\n",
      "11: 96 Tweets downloaded in this batch. with last tweet: 2021-07-26T21:14:00.000Z\n",
      "12: 100 Tweets downloaded in this batch. with last tweet: 2021-07-26T16:10:28.000Z\n",
      "13: 95 Tweets downloaded in this batch. with last tweet: 2021-07-26T13:23:23.000Z\n",
      "14: 99 Tweets downloaded in this batch. with last tweet: 2021-07-26T12:31:36.000Z\n",
      "15: 99 Tweets downloaded in this batch. with last tweet: 2021-07-26T11:24:19.000Z\n",
      "16: 67 Tweets downloaded in this batch. with last tweet: 2021-07-26T10:06:40.000Z\n",
      "17: 93 Tweets downloaded in this batch. with last tweet: 2021-07-26T04:36:59.000Z\n",
      "18: 96 Tweets downloaded in this batch. with last tweet: 2021-07-26T02:00:56.000Z\n",
      "19: 95 Tweets downloaded in this batch. with last tweet: 2021-07-26T01:14:34.000Z\n",
      "20: 94 Tweets downloaded in this batch. with last tweet: 2021-07-26T00:32:46.000Z\n",
      "21: 93 Tweets downloaded in this batch. with last tweet: 2021-07-26T00:02:27.000Z\n",
      "22: 89 Tweets downloaded in this batch. with last tweet: 2021-07-25T23:40:05.000Z\n",
      "23: 78 Tweets downloaded in this batch. with last tweet: 2021-07-25T21:00:12.000Z\n",
      "24: 99 Tweets downloaded in this batch. with last tweet: 2021-07-25T17:04:48.000Z\n",
      "25: 98 Tweets downloaded in this batch. with last tweet: 2021-07-25T15:19:23.000Z\n",
      "26: 95 Tweets downloaded in this batch. with last tweet: 2021-07-25T13:24:31.000Z\n",
      "27: 77 Tweets downloaded in this batch. with last tweet: 2021-07-25T12:02:01.000Z\n",
      "28: 98 Tweets downloaded in this batch. with last tweet: 2021-07-25T09:55:58.000Z\n",
      "29: 100 Tweets downloaded in this batch. with last tweet: 2021-07-25T09:07:27.000Z\n",
      "Tweets batch 5 stored in pkl file\n",
      "0: 98 Tweets downloaded in this batch. with last tweet: 2021-07-25T08:12:33.000Z\n",
      "1: 99 Tweets downloaded in this batch. with last tweet: 2021-07-25T07:39:34.000Z\n",
      "2: 99 Tweets downloaded in this batch. with last tweet: 2021-07-25T07:04:29.000Z\n",
      "3: 99 Tweets downloaded in this batch. with last tweet: 2021-07-25T06:27:48.000Z\n",
      "4: 99 Tweets downloaded in this batch. with last tweet: 2021-07-25T04:43:16.000Z\n",
      "5: 97 Tweets downloaded in this batch. with last tweet: 2021-07-25T03:12:41.000Z\n",
      "6: 96 Tweets downloaded in this batch. with last tweet: 2021-07-25T01:50:19.000Z\n",
      "7: 95 Tweets downloaded in this batch. with last tweet: 2021-07-25T00:49:07.000Z\n",
      "8: 98 Tweets downloaded in this batch. with last tweet: 2021-07-24T18:52:22.000Z\n",
      "9: 96 Tweets downloaded in this batch. with last tweet: 2021-07-24T13:12:22.000Z\n",
      "10: 94 Tweets downloaded in this batch. with last tweet: 2021-07-24T12:02:42.000Z\n",
      "11: 100 Tweets downloaded in this batch. with last tweet: 2021-07-24T09:36:28.000Z\n",
      "12: 98 Tweets downloaded in this batch. with last tweet: 2021-07-24T07:49:35.000Z\n",
      "13: 98 Tweets downloaded in this batch. with last tweet: 2021-07-24T04:36:48.000Z\n",
      "14: 96 Tweets downloaded in this batch. with last tweet: 2021-07-24T01:23:07.000Z\n",
      "15: 96 Tweets downloaded in this batch. with last tweet: 2021-07-23T17:51:39.000Z\n",
      "16: 93 Tweets downloaded in this batch. with last tweet: 2021-07-23T11:01:59.000Z\n",
      "17: 97 Tweets downloaded in this batch. with last tweet: 2021-07-22T22:40:03.000Z\n",
      "18: 97 Tweets downloaded in this batch. with last tweet: 2021-07-22T08:15:14.000Z\n",
      "19: 99 Tweets downloaded in this batch. with last tweet: 2021-07-21T23:22:33.000Z\n",
      "20: 97 Tweets downloaded in this batch. with last tweet: 2021-07-21T07:56:48.000Z\n",
      "21: 95 Tweets downloaded in this batch. with last tweet: 2021-07-20T09:30:55.000Z\n",
      "22: 95 Tweets downloaded in this batch. with last tweet: 2021-07-19T11:46:39.000Z\n",
      "23: 93 Tweets downloaded in this batch. with last tweet: 2021-07-18T05:01:24.000Z\n",
      "24: 34 Tweets downloaded in this batch. with last tweet: 2021-07-16T14:52:31.000Z\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "tweets = get_data(\"(#gymnastics) lang:en -is:retweet\",\n",
    "         start_time = \"2021-07-15T00:00:00Z\",\n",
    "         end_time = \"2021-08-15T00:00:00Z\",\n",
    "         max_results=100,\n",
    "         expansions='entities.mentions.username,referenced_tweets.id.author_id',\n",
    "         tweet_fields='id,text,author_id,created_at,entities',\n",
    "         user_fields='id,name,username,description',\n",
    "         place_fields='full_name,id,country,country_code,geo,name,place_type',\n",
    "         endpoint=\"https://api.twitter.com/2/tweets/search/all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_df = pd.DataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_df.to_pickle(path+\"tweets.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OxPOkg0Sgq0E",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 4: individual work\n",
    "\n",
    "- think of a topic you'd like to read some tweets from\n",
    "- build a query (play around with the logic - can you get only tweets that are not a retweet?)\n",
    "- how many tweets did you get?\n",
    "- what if you changed the date range?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "ffccf19f5bea3c345c854d505af45eafe6890432f50bcc58a653a75b25e4385b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
